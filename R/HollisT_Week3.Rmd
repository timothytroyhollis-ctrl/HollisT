---
title: "HollisT_Week3"
author: "Tim Hollis"
date: "`r Sys.Date()`"
output: html_document
---
Assignment:

Taking the same data set from Week 2, use R to create all of the descriptive statistical values and plots you learned this week. This week, R Markdown should be used to explain the statistical meaning and importance of what you’re doing; be critical, curious, and opinionated.



Specifically, for each numeric attribute in the dataset:



Show the distributions of values visually. Explain, in comments, what those distributions mean statistically. Be thorough.
Show the values of central tendency, both numerically and visually. Interpret those values in your own words in Markdown.
Show the measures of dispersion, visually and numerically (where appropriate). Interpret those values in Markdown.
Visually depict the Interquartile range. Interpret the IQR for the dataset (in Markdown).
Create the statistics moments for the dataset.
Experiment with histogram binning for the categorical data in R. This is open-ended intentionally because this dataset isn’t ideal for binning, but I want you to build something using binning just to see how it works.





```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#Load Libraries
library(tidyverse)  #Includes ggplot2, dplyr, etc.
library(moments)    #For skewness and kurtosis
library(scales)     #For currency formatting
library(readxl)     #To read Excel files
library(kableExtra) #To edit table formatting
library(rlang)      #For symbol handling
library(patchwork)  #For combining multiple plots into one layout
library(e1071)      #Alt functions for statistical moments

#Load Data
fdata<-read_excel('R_formatted_data.xlsx')
rdata<-read.csv('week2_data.csv')


#Review structure of dataset
str(fdata)
```

```{r data-audit,message=FALSE,warning=FALSE}

#Audit Data
fdata<-fdata %>%
  mutate(
    CorrectedSales=Quantity*UnitPrice,
    Difference=CorrectedSales-TotalSales
  )

#Count mismatches
fdata %>%
  filter(Difference!=0) %>% 
  nrow()

#View mismatched rows
fdata %>%
  filter(Difference!=0) %>%
  select(OrderID,Quantity,UnitPrice,CorrectedSales,Difference)
```

### Week 3 R Markdown — A Critical, Curious, and Happily Opinionated Exploration

#### My Descriptive Statistical Analysis and Interpretation of the Data

The first step in this week’s R Markdown file is to load the formatted dataset and the libraries needed to edit and analyze that data. Now that is complete, it’s time to tune in to what the dataset is actually saying.

### Distribution of Numeric Variables

To begin my statistical analysis, I’m focusing on the distribution of financial values, specifically the price of each unit and the total sales for each order. These two variables reflect the monetary behavior embedded in the dataset.

### Data Audit Summary

Before diving into these distributions, I conducted a data audit to verify the integrity of the TotalSales column and recalculating as Quantity × UnitPrice. This revealed 260 discrepancies, some of which were substantial, not simple rounding errors.To ensure analytical integrity, I created a new column, CorrectedSales, which reflects the verified sales values. All subsequent analysis including summary statistics, visualizations, and interpretations, will use CorrectedSales rather than the original TotalSales field. This decision prioritizes accuracy and transparency.

Visualizing these distributions helps reveal patterns such as skewness, clustering, and outliers.The following histograms provide a first look at how unit prices and corrected sales values are spread out within the dataset.

```{r histogram-distribution,fig.width=7,fig.height=5}
#Define numeric variables for distribution analysis
numeric_vars<-c('UnitPrice','CorrectedSales')

#Create histograms for each variable
for (var in numeric_vars) {
  p<-ggplot(fdata,aes(x=!!sym(var)))+
    geom_histogram(binwidth=10,fill='steelblue',color='white')+
    labs(
      title=paste('Distribution of',var),
      x=var,
      y='Frequency'
    )+
    theme_minimal()->p
  print(p)
}
```

### Interpreting the Distribution of Financial Variables

The histograms in the previous section show how `UnitPrice` and `CorrectedSales` are distributed across the dataset. While the first bin appeared to show unit prices at \$0, this was a result of binning, the bar actually represents all prices from \$0 to \$10. There are no true zero-priced items in the dataset, which confirms the integrity of the pricing data.

Most unit prices fall between \$30 and \$40, with a secondary concentration between \$80 and \$90. This bimodal pattern suggests that the dataset may include both standard and premium product tiers. The presence of two distinct pricing clusters could reflect intentional segmentation, such as budget vs. high-end offerings—or simply variability in product types.

These pricing patterns are important because they influence which statistical measures are most appropriate, especially when distributions are skewed or contain outliers. Understanding this structure helps clarify whether the mean or median is a more reliable indicator of central tendency.

```{r Unit-Price-by-Region,fig.width=7,fig.height=5}
#Boxplot of Unit Price by Region
ggplot(fdata,aes(x=Region,y=UnitPrice))+
  geom_boxplot(fill='lightblue',color='darkblue')+
  stat_summary(
    fun=median,
    geom='text',
    aes(label=scales::dollar_format(accuracy=0.01)(after_stat(y))),
    vjust=-0.5,
    color='black',
    size=3.5
  )+
  labs(
    title='Unit Price by Region',
    x='Region',
    y='UnitPrice'
  )+
  theme_minimal()
```

```{r Total-Sales-by-Region,fig.width=7,fig.height=5}
#Boxplot of Total Sales by Region
ggplot(fdata,aes(x=Region,y=CorrectedSales))+
  geom_boxplot(fill='lightgreen',color='darkgreen')+
  stat_summary(
    fun=median,
    geom='text',
    aes(label=scales::dollar_format(accuracy=0.01)(after_stat(y))),
    vjust=-0.5,
    color='black',
    size=3.5
  )+
  labs(
    title='Total Sales by Region',
    x='Region',
    y='Total Sales'
  )+
  theme_minimal()
```

### Interpreting Regional Segmentation

While the previous distributions offer a useful starting point, they don’t explain *where* these patterns originate. To deepen the analysis, I explored whether certain regions tend to order higher-priced products, and whether high-value orders are concentrated in specific areas.

The data shows that the East region tends to order higher-priced units, while the West leans toward lower-priced ones. This is supported by the average total order values: East averages around \$375.10 per order, while West averages roughly \$346.44. The East and South regions are almost identical in both average price of sale and the number of outliers with one a piece, there is a slightly bigger average price difference per order with North and West, though the number of outliers they both have, are almost identical.

These patterns suggest that East and West exhibit more consistent purchasing behavior, with East favoring higher-priced units and West leaning toward lower-cost options. In contrast, North and South show greater variability—both in average order value and in the spread of unit prices. While East and South are nearly identical in average sales and each has only one outlier, North and West differ more in average order value, yet share a similar number of outliers. This variability may reflect differences in product mix, order size, or purchase strategy, and is important to consider when selecting appropriate summary statistics. Measures like the median may offer a more reliable view than the mean in regions with wider dispersion or skewed distributions.

### Measures of Central Tendency

Now that I’ve explored regional differences in pricing and order value, I am now moving on to define what’s “typical” across the dataset. Measures of central tendency help summarize the core behavior of financial variables. I’ll focus on the Unit Price and Corrected Sales, as they reflect the monetary value of individual products and entire orders, respectively.

These metrics offer different perspectives: - The mean captures the average value, but can be skewed by outliers. - The median shows the midpoint, and clearer view when distributions are uneven. - The mode identifies the most frequently occurring value, which can highlight pricing strategy or popular order sizes.

```{r central-tendency-summary}

#Mode Function
get_mode<-function(v){
  freq_table<-table(v)
  mode_val<-names(freq_table)[which.max(freq_table)]
  as.numeric(mode_val)
}

#Create and format table
central_tendency_table<-tibble(
  Measure=c('Mean','Median','Mode'),
  UnitPrice=c(
    mean(fdata$UnitPrice),
    median(fdata$UnitPrice),
    get_mode(fdata$UnitPrice)
  ),
  CorrectedSales=c(
    mean(fdata$CorrectedSales),
    median(fdata$CorrectedSales),
    get_mode(fdata$CorrectedSales)
  )
) %>%
  mutate(
    UnitPrice=dollar(UnitPrice,accuracy=0.01),
    CorrectedSales=dollar(CorrectedSales,accuracy=0.01)
  )

#Display formatted table

central_tendency_table %>%
  kable(caption='<span style="color:#000000;font-weight:bold;">Central Tendencies</span>') %>%
  kable_styling(
    bootstrap_options=c('striped','hover','condensed'),
    full_width=FALSE,
    position='center'
  )
```

### Interpreting Central Tendency

The central tendency metrics offer a snapshot of typical financial behavior across the dataset. For UnitPrice, the mean (\$52.41) and median (\$50.97) are closely aligned, suggesting a relatively symmetrical distribution with minimal skew. However, the mode (\$19.23) reveals a popular low-cost item, indicating that while most prices cluster around \$50, one specific product is ordered frequently at a much lower price point.

For CorrectedSales, the mean (\$506.70) is significantly higher than the median (\$370.24), which suggests a right-skewed distribution—likely driven by large orders or high-quantity purchases. The mode (\$32.47) reflects the most common small-order value, reinforcing the idea that while most orders are modest, a few high-value transactions pull the average upward.

These patterns confirm that the median is a more reliable indicator of typical behavior for CorrectedSales, while the mode offers insight into popular pricing and order habits. This context will guide how I interpret variability and outliers in the next section.

### Measures of Dispersion and Spread

To understand how much variability exists in the dataset, I calculated key measures of dispersion for both UnitPrice and CorrectedSales. These include the standard deviation, range, and interquartile range (IQR).

Dispersion metrics help reveal whether values are tightly clustered or widely spread, which influences how representative the central tendency measures are. I also visualized the IQR using boxplots to highlight the middle 50% of values and identify potential outliers.

```{r Dispersion-summary,fig.width=7,fig.height=5}
#Dispersion metrics
dispersion_table<-tibble(
  Measure=c('Standard Deviation','Range','IQR'),
  UnitPrice=c(
    sd(fdata$UnitPrice),
    max(fdata$UnitPrice)-min(fdata$UnitPrice),
    IQR(fdata$UnitPrice)
  ),
  CorrectedSales=c(
    sd(fdata$CorrectedSales),
    max(fdata$CorrectedSales)-min(fdata$CorrectedSales),
    IQR(fdata$CorrectedSales)
  )
)

#Format as Currency
dispersion_table<-dispersion_table %>%
  mutate(
    UnitPrice=dollar(UnitPrice,accuracy=0.01),
    CorrectedSales=dollar(CorrectedSales,accuracy=0.01)
  )


#Display formatted table
dispersion_table %>%
  kable(caption='<span style="color:000000;font-weight:bold;">
  Measures of Dispersion</span>') %>%
  kable_styling(
    bootstrap_options=c('striped','hover','condensed'),
    full_width=FALSE,
    position='center'
  )

#Boxplot for UnitPrice
p1<-ggplot(fdata,aes(x='',y=UnitPrice))+
  geom_boxplot(fill='lightcoral',color='darkred')+
  stat_summary(
    fun=median,
    geom='text',
    aes(label=after_stat(y)),
    vjust=-0.5,
    color='black',
    size=3.5
  )+
  scale_y_continuous(labels=scales::dollar_format(accuracy=0.01))+
  labs(title='Boxplot of UnitPrice',x='',y='UnitPrice')+
  theme_minimal()

#Boxplot for CorrectedSales
p2<-ggplot(fdata,aes(x='',y=CorrectedSales))+
  geom_boxplot(fill='lightcoral',color='darkred')+
  stat_summary(
    fun=median,
    geom='text',
    aes(label=after_stat(y)),
    vjust=-0.5,
    color='black',
    size=3.5
  )+
  scale_y_continuous(labels=scales::dollar_format(accuracy=0.01))+
  labs(title='Boxplot of CorrectedSales',x='',y='CorrectedSales')+
  theme_minimal()

#Display plots side by side
p1+p2
```

### Interpreting Measures of Dispersion

The measures of dispersion reveal how spread out the financial values are across the dataset. For UnitPrice, the standard deviation is \$28.69, and the range spans \$143.10, indicating moderate variability in product pricing. The IQR of \$50.45 shows that the middle 50% of unit prices are tightly clustered, showing a relatively consistent pricing strategy with few extreme values.

In contrast, CorrectedSales exhibits far greater variability. The standard deviation is \$449.79, and the range stretches a dramatic \$2,264.40. The IQR of \$622.77 confirms that even the middle 50% of order values are widely dispersed. This is visually reinforced by the boxplot, which shows several high-value outliers pulling the upper whisker far above the median.

These patterns suggest that while product pricing is relatively stable, order values fluctuate significantly, likely due to differences in quantity purchased or product mix. This reinforces the earlier conclusion that median is a more reliable summary for CorrectedSales, while mean and IQR offer useful insights into pricing consistency for UnitPrice.

```{r statistical-moments}
moments_table<-tibble(
  Measure=c('Skewness','Kurtosis'),
  UnitPrice=c(
    skewness(fdata$UnitPrice),
    kurtosis(fdata$UnitPrice)
  ),
  CorrectedSales=c(
    skewness(fdata$CorrectedSales),
    kurtosis(fdata$CorrectedSales)
  )
)

moments_table %>%
  mutate(
    UnitPrice=round(UnitPrice,2),
    CorrectedSales=round(CorrectedSales,2)
  ) %>%
  kable(
    caption='<span style="color:#000000;font-weight:bold;">
    Statistical Moments</span>'
  ) %>%
  kable_styling(
    bootstrap_options=c('striped','hover','condensed'),
    full_width=FALSE,
    position='center'
  )
```

### Interpreting Statistical Moments

The skewness and kurtosis values offer insight into the shape and behavior of each distribution beyond what central tendency and dispersion can show.

For UnitPrice, the skewness is approximately 0.09, a nearly symmetrical distribution. The kurtosis of -1.12 suggests a flatter, more uniform shape than a normal distribution, meaning prices are spread out more evenly, with fewer extreme values. This aligns with prior findings that unit prices are relatively stable and clustered.

In contrast, CorrectedSales shows a skewness of 1.13, confirming a right-skewed distribution. This means that while most orders are modest, a few high-value transactions stretch the tail to the right. The kurtosis of 0.69 indicates a slightly heavier tail than normal, reinforcing the presence of outliers and extreme values.

These metrics validate the earlier decision to rely on the median and IQR for interpreting CorrectedSales, while UnitPrice can be reasonably summarized using the mean and standard deviation.

```{r histogram-binning,fig.width=7,fig.height=5}
#Create binned UnitPrice categories

bin_edges<-seq(0,ceiling(max(fdata$UnitPrice))+25,by=25)
bin_labels<-paste0('$',head(bin_edges,-1),'-$',tail(bin_edges,-1))
fdata<-fdata %>%
  mutate(UnitPriceBin=cut(
    UnitPrice,
    breaks=bin_edges,
    labels=bin_labels,
    include.lowest=TRUE,
    right=FALSE
  ))

#Count by bin and Region
bin_counts<-fdata %>%
  count(UnitPriceBin,Region)

#Plot as faceted bar chart
ggplot(bin_counts,aes(x=UnitPriceBin,y=n,fill=Region))+
  geom_bar(stat='identity',position='dodge')+
  labs(
    title='Binned UnitPrice by Region',
    x='Unit Price Bin',
    y='Count'
  )+
  theme_minimal()+
  theme(axis.text.x=element_text(angle=45,hjust=1))
```

### Interpreting Binned UnitPrice by Region

This visualization breaks down UnitPrice into \$25-wide bins and compares how often products fall into each range across regions: East, North, South,and West.

While the \$25–\$50 bin shows strong activity overall, it is not the dominant ange across all regions. In fact, the South region has its highest concentration in this bin, suggesting a preference for mid-range pricing.

The East and North regions show their highest counts in the \$75–\$100 bin, indicating a tilt toward higher-priced products. Meanwhile, the West peaks in the \$0–\$25 bin, suggesting a focus on lower-cost offerings.

These regional differences may reflect variations in product mix, customer demographics, or pricing strategies

```{r histogram-correctedsales,fig.width=7,fig.height=5}

#Create binned CorrectedSales categories
bin_edges<-seq(0,ceiling(max(fdata$CorrectedSales))+250,by=250)
bin_labels<-paste0('$',head(bin_edges,-1),'-$',tail(bin_edges,-1))

fdata<-fdata %>%
  mutate(CorrectedSalesBin=cut(
    CorrectedSales,
    breaks=bin_edges,
    labels=bin_labels,
    include.lowest=TRUE,
    right=FALSE
  ))

#Count by bin and Region

sales_bin_counts<-fdata %>%
  count(CorrectedSalesBin,Region)

#Plot as faceted bar chart
ggplot(sales_bin_counts,aes(x=CorrectedSalesBin,y=n,fill=Region))+
  geom_bar(stat='identity',position='dodge')+
  labs(
    title='Binned CorrectedSales by Region',
    x='Corrected Sales Bin',
    y='Count',
  )+
  theme_minimal()+
  theme(axis.text.x=element_text(angle=45,hjust=1))
```

### Interpreting Binned CorrectedSales by Region

This chart bins CorrectedSales into \$250-wide ranges and compares how frequently orders fall into each range across four regions: East, North, South, and West.

The \$0–\$250 bin is the dominant category across all four regions, showing that most orders are modest in value. This reflects a consistent baseline of smaller transactions regardless of geography.

In the \$250–\$500 bin, the North region leads in count, while East and South tie for second, supporting moderate-value orders are more common in these areas.

The \$500–\$750 bin sees the highest activity from West and North, hinting at a mix of larger purchases or bundled transactions.

Interestingly, the \$750–\$1,000 bin is most active in the South and West, showing that these regions also handle a notable share of high-value orders.

These regional differences reinforce earlier findings about the wide dispersion and skewness in CorrectedSales. They may reflect variations in customer behavior, product mix, or promotional strategies, and they underscore the importance of using median and IQR when the financial metrics have heavy tails and outliers.

## Reflections for Week 3

### The Less Challenging

This assignment offered a valuable opportunity to explore the shape and behavior of financial data using summary statistics and visualizations. Some portions felt intuitive, like calculating mean, median, and mode, and interpreting boxplots to highlight central tendency and spread. These steps helped reinforce the importance of choosing the right summary metrics for different types of data.

### The More Challenging

The more challenging aspects involved interpreting statistical moments like skewness and kurtosis, and designing binning logic for histogram-style comparisons across regions. These required deeper attention to how R handles breaks, labels, and edge cases when translating numeric distributions into categorical bins.

### My Biggest Learnings

Visualizing dispersion through IQR and boxplots helped clarify which metrics were most reliable for skewed data, while the regional breakdowns revealed at times subtle, yet meaningful differences in pricing and sales behavior.

Overall, this assignment strengthened my ability to narrate data clearly, troubleshoot binning logic, and present insights that go beyond surface-level summaries. I’m excited to carry these skills forward into future analyses.

### Week 3 RMarkdown using Raw Data for TotalSales

### Intro to Raw Data Analysis

Before applying any corrections or preprocessing, it was essential to understand
the behavior of the original dataset. The following visualizations and summary 
tables explore the raw TotalSales values with UnitPrice, offering a baseline 
view of distribution, central tendency, dispersion, and regional segmentation.

This unaltered data reflects the initial state of reporting and may containt
inconsistencies, outliers, and missing values. By examining these metrics in 
their raw form, I was able to gain insight into how noise and irregularities may
influence interpretation. This step highlights the impact of data cleaning 
and helps justify the need for correction.


#### Distribution of Numeric Variables

```{r histogram-distribution-rawdata,fig.width=7,fig.height=5}
#Define numeric variables for distribution analysis
numeric_vars<-c('UnitPrice','TotalSales')

#Create histograms for each variable
for (var in numeric_vars) {
  p<-ggplot(rdata,aes(x=!!sym(var)))+
    geom_histogram(binwidth=10,fill='steelblue',color='white')+
    labs(
      title=paste('Distribution of',var),
      x=var,
      y='Frequency'
    )+
    theme_minimal()->p
  print(p)
}
```

#### Regional Segmentation

```{r Unit-Price-TotalSales-by-Region-rawdata,fig.width=7,fig.height=5}
#Boxplot of Unit Price by Region
ggplot(rdata,aes(x=Region,y=UnitPrice))+
  geom_boxplot(fill='lightblue',color='darkblue')+
  stat_summary(
    fun=median,
    geom='text',
    aes(label=scales::dollar_format(accuracy=0.01)(after_stat(y))),
    vjust=-0.5,
    color='black',
    size=3.5
  )+
  labs(
    title='Unit Price by Region',
    x='Region',
    y='UnitPrice'
  )+
  theme_minimal()

#Boxplot of Total Sales by Region
ggplot(rdata,aes(x=Region,y=TotalSales))+
  geom_boxplot(fill='lightgreen',color='darkgreen')+
  stat_summary(
    fun=median,
    geom='text',
    aes(label=scales::dollar_format(accuracy=0.01)(after_stat(y))),
    vjust=-0.5,
    color='black',
    size=3.5
  )+
  labs(
    title='Total Sales by Region',
    x='Region',
    y='Total Sales'
  )+
  theme_minimal()
```

#### Central Tendency

```{r central-tendency-summary-rawdata}

#Mode Function
get_mode<-function(v){
  freq_table<-table(v)
  mode_val<-names(freq_table)[which.max(freq_table)]
  as.numeric(mode_val)
}

#Create and format table
central_tendency_table<-tibble(
  Measure=c('Mean','Median','Mode'),
  UnitPrice=c(
    mean(rdata$UnitPrice),
    median(rdata$UnitPrice),
    get_mode(rdata$UnitPrice)
  ),
  TotalSales=c(
    mean(rdata$TotalSales),
    median(rdata$TotalSales),
    get_mode(rdata$TotalSales)
  )
) %>%
  mutate(
    UnitPrice=dollar(UnitPrice,accuracy=0.01),
   TotalSales=dollar(TotalSales,accuracy=0.01)
  )

#Display formatted table

central_tendency_table %>%
  kable(caption='<span style="color:#000000;font-weight:bold;">Central Tendencies</span>') %>%
  kable_styling(
    bootstrap_options=c('striped','hover','condensed'),
    full_width=FALSE,
    position='center'
  )
```

#### Dispersion and Spread

```{r Dispersion-summary-rawdata,fig.width=7,fig.height=5}
#Dispersion metrics
dispersion_table<-tibble(
  Measure=c('Standard Deviation','Range','IQR'),
  UnitPrice=c(
    sd(rdata$UnitPrice),
    max(rdata$UnitPrice)-min(rdata$UnitPrice),
    IQR(rdata$UnitPrice)
  ),
  TotalSales=c(
    sd(rdata$TotalSales),
    max(rdata$TotalSales)-min(rdata$TotalSales),
    IQR(rdata$TotalSales)
  )
)

#Format as Currency
dispersion_table<-dispersion_table %>%
  mutate(
    UnitPrice=dollar(UnitPrice,accuracy=0.01),
    TotalSales=dollar(TotalSales,accuracy=0.01)
  )


#Display formatted table
dispersion_table %>%
  kable(caption='<span style="color:000000;font-weight:bold;">
  Measures of Dispersion</span>') %>%
  kable_styling(
    bootstrap_options=c('striped','hover','condensed'),
    full_width=FALSE,
    position='center'
  )

#Boxplot for UnitPrice
p1<-ggplot(rdata,aes(x='',y=UnitPrice))+
  geom_boxplot(fill='lightcoral',color='darkred')+
  stat_summary(
    fun=median,
    geom='text',
    aes(label=after_stat(y)),
    vjust=-0.5,
    color='black',
    size=3.5
  )+
  scale_y_continuous(labels=scales::dollar_format(accuracy=0.01))+
  labs(title='Boxplot of UnitPrice',x='',y='UnitPrice')+
  theme_minimal()

#Boxplot for TotalSales
p2<-ggplot(rdata,aes(x='',y=TotalSales))+
  geom_boxplot(fill='lightcoral',color='darkred')+
  stat_summary(
    fun=median,
    geom='text',
    aes(label=after_stat(y)),
    vjust=-0.5,
    color='black',
    size=3.5
  )+
  scale_y_continuous(labels=scales::dollar_format(accuracy=0.01))+
  labs(title='Boxplot of TotalSales',x='',y='TotalSales')+
  theme_minimal()

#Display plots side by side
p1+p2
```

#### Skewness and Kurtosis

```{r statistical-moments-rawdata}
moments_table<-tibble(
  Measure=c('Skewness','Kurtosis'),
  UnitPrice=c(
    skewness(rdata$UnitPrice),
    kurtosis(rdata$UnitPrice)
  ),
  TotalSales=c(
    skewness(rdata$TotalSales),
    kurtosis(rdata$TotalSales)
  )
)

moments_table %>%
  mutate(
    UnitPrice=round(UnitPrice,2),
    TotalSales=round(TotalSales,2)
  ) %>%
  kable(
    caption='<span style="color:#000000;font-weight:bold;">
    Statistical Moments</span>'
  ) %>%
  kable_styling(
    bootstrap_options=c('striped','hover','condensed'),
    full_width=FALSE,
    position='center'
  )
```

#### Binned Unit Price and Total Sales

```{r histogram-binning-rawdata,fig.width=7,fig.height=5}
#Create binned UnitPrice categories

bin_edges<-seq(0,ceiling(max(rdata$UnitPrice))+25,by=25)
bin_labels<-paste0('$',head(bin_edges,-1),'-$',tail(bin_edges,-1))
rdata<-rdata %>%
  mutate(UnitPriceBin=cut(
    UnitPrice,
    breaks=bin_edges,
    labels=bin_labels,
    include.lowest=TRUE,
    right=FALSE
  ))

#Count by bin and Region
bin_counts<-rdata %>%
  count(UnitPriceBin,Region)

#Plot as faceted bar chart
ggplot(bin_counts,aes(x=UnitPriceBin,y=n,fill=Region))+
  geom_bar(stat='identity',position='dodge')+
  labs(
    title='Binned UnitPrice by Region',
    x='Unit Price Bin',
    y='Count'
  )+
  theme_minimal()+
  theme(axis.text.x=element_text(angle=45,hjust=1))

#Create binned TotalSales categories
bin_edges<-seq(0,ceiling(max(rdata$TotalSales))+250,by=250)
bin_labels<-paste0('$',head(bin_edges,-1),'-$',tail(bin_edges,-1))

rdata<-rdata %>%
  mutate(TotalSalesBin=cut(
    TotalSales,
    breaks=bin_edges,
    labels=bin_labels,
    include.lowest=TRUE,
    right=FALSE
  ))

#Count by bin and Region

sales_bin_counts<-rdata %>%
  count(TotalSalesBin,Region)

#Plot as faceted bar chart
ggplot(sales_bin_counts,aes(x=TotalSalesBin,y=n,fill=Region))+
  geom_bar(stat='identity',position='dodge')+
  labs(
    title='Binned TotalSales by Region',
    x='Corrected Sales Bin',
    y='Count',
  )+
  theme_minimal()+
  theme(axis.text.x=element_text(angle=45,hjust=1))
```

### Reflection on Raw Data Insights

The raw data analysis reveals a landscape shaped by variability and 
underreporting. TotalSales values tend to cluster in lower ranges, with wider 
dispersion and less consistent regional patterns. While useful for exploratory 
purposes, this version of the dataset lacks the clarity and reliability needed 
for confident decision-making.

Comparing these results to the cleaned CorrectedSales analysis highlights the 
importance of preprocessing, not just for removing errors, but for restoring 
completeness. The raw data tells a fragmented story; the cleaned data fills in 
the gaps. Together, they illustrate the transformation from noise to narrative.


